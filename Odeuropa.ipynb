{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbR14wBaGxVGl2kjTPsnxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miokasa/Odeuropa/blob/main/Odeuropa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7Fo9YsJYa99",
        "outputId": "6c088d34-8d7b-4322-ba19-4c8789709bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/Odeuropa/webanno.zip -d /content/drive/MyDrive/Odeuropa/webanno"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rT6-lXshYgU5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of folds for train/dev/test"
      ],
      "metadata": {
        "id": "OdpbT7lo_q7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/Odeuropa/create_folds.py \\\n",
        "  --folder /content/drive/MyDrive/Odeuropa/webanno \\\n",
        "  --output /content/drive/MyDrive/Odeuropa/folds_output \\\n",
        "  --tasktype BERT \\\n",
        "  --tags Smell\\\\_Word,Smell\\\\_Source,Quality"
      ],
      "metadata": {
        "id": "YIust6E3yzoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ede7654-296a-447e-95be-ee12ddcee144"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tag: {'Circumstances': 0, 'Effect': 1, 'Evoked\\\\_Odorant': 2, 'Location': 3, 'Odour\\\\_Carrier': 4, 'Perceiver': 5, 'Quality': 6, 'Smell\\\\_Source': 7, 'Smell\\\\_Word': 8, 'Time': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert English plain texts to Bert format for the classification"
      ],
      "metadata": {
        "id": "c86CLdyr_vi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/Odeuropa/DocumentsEN.csv\"\n",
        "save_path = \"/content/drive/MyDrive/Odeuropa/books_raw\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    doc_id = str(row['Document Identifier']) + \".txt\"\n",
        "    url = row['Link to source']\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.encoding = response.apparent_encoding\n",
        "        if url.endswith(\".txt\"):\n",
        "            text = response.text\n",
        "        else:\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            if \"wikisource\" in url:\n",
        "                main_text = soup.find(\"div\", {\"class\": \"mw-parser-output\"})\n",
        "            elif \"umich.edu\" in url:\n",
        "                main_text = soup.find(\"div\", {\"class\": \"text\"})\n",
        "            else:\n",
        "                main_text = soup.get_text()\n",
        "\n",
        "            if main_text:\n",
        "                text = main_text.get_text(separator=\"\\n\")\n",
        "            else:\n",
        "                text = soup.get_text()\n",
        "\n",
        "        with open(os.path.join(save_path, doc_id), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text)\n",
        "\n",
        "        print(f\"Saved {doc_id}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to fetch {doc_id} from {url}: {e}\")\n"
      ],
      "metadata": {
        "id": "U4t1KdqM0FJt",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b387696-70d0-467e-dca3-ba873a586b96"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 001E.txt\n",
            "Saved 002E.txt\n",
            "Saved 003E.txt\n",
            "Saved 004E.txt\n",
            "Saved 005E.txt\n",
            "Failed to fetch 006E.txt from https://wellcomelibrary.org/moh/report/b19874455/8#?c=0&m=0&s=0&cv=0: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 007E.txt from https://www.gutenberg.org/files/60584/60584-h/60584-h.htm: 'str' object has no attribute 'get_text'\n",
            "Saved 008E.txt\n",
            "Saved 009E.txt\n",
            "Failed to fetch 010E.txt from https://www.gutenberg.org/files/829/829-h/829-h.htm: 'str' object has no attribute 'get_text'\n",
            "Saved 011E.txt\n",
            "Saved 012E.txt\n",
            "Saved 013E.txt\n",
            "Saved 014E.txt\n",
            "Saved 015E.txt\n",
            "Saved 016E.txt\n",
            "Failed to fetch 017E.txt from https://archive.org/details/b20398177: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 018E.txt from https://archive.org/details/b21481246: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 019E.txt from https://archive.org/details/b2041075x: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 020E.txt from https://archive.org/details/b28116598/page/n1/mode/2up: 'str' object has no attribute 'get_text'\n",
            "Saved 021E.txt\n",
            "Failed to fetch 022E.txt from https://gutenberg.org/files/49461/49461-h/49461-h.htm: 'str' object has no attribute 'get_text'\n",
            "Saved 023E.txt\n",
            "Saved 024E.txt\n",
            "Saved 025E.txt\n",
            "Saved 026E.txt\n",
            "Failed to fetch 027E.txt from http://www.earlystuartlibels.net/htdocs/king_and_favorite_section/L8.html: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 028E.txt from https://babel.hathitrust.org/cgi/pt?id=chi.64463214: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 029E.txt from https://archive.org/details/b28072467: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 030E.txt from https://archive.org/details/foodinspectorsha00vachrich: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 031E.txt from https://archive.org/details/nuisanceofneighb00ball/page/4/mode/2up: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 032E.txt from https://archive.org/details/b2135876x: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 033E.txt from https://gutenberg.org/files/376/376-h/376-h.htm: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 034E.txt from https://gutenberg.org/files/2153/2153-h/2153-h.htm: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 035E.txt from https://www.gutenberg.org/files/40882/40882-h/40882-h.htm: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 036E.txt from https://gutenberg.org/files/174/174-h/174-h.htm: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 037E.txt from http://gutenberg.net.au/ebooks03/0301041h.html: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 038E.txt from https://www.gutenberg.org/ebooks/author/1529: 'str' object has no attribute 'get_text'\n",
            "Saved 039E.txt\n",
            "Failed to fetch 040E.txt from https://wellcomelibrary.org/moh/report/b18253386#?c=0&m=0&s=0&cv=0&z=-0.9751%2C0.0976%2C2.9703%2C1.2314: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 041E.txt from https://archive.org/details/63050860R.nlm.nih.gov: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 042E.txt from https://archive.org/details/dissertationonen00hoff: 'str' object has no attribute 'get_text'\n",
            "Saved 043E.txt\n",
            "Saved 044E.txt\n",
            "Saved 045E.txt\n",
            "Saved 046E.txt\n",
            "Failed to fetch 047E.txt from https://www.gutenberg.org/files/1039/1039-h/1039-h.htm: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 048E.txt from https://www.gutenberg.org/files/32977/32977-h/32977-h.htm: 'str' object has no attribute 'get_text'\n",
            "Saved 049E.txt\n",
            "Saved 050E.txt\n",
            "Failed to fetch 051E.txt from https://royalsocietypublishing.org/doi/10.1098/rspl.1837.0114: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 052E.txt from https://royalsocietypublishing.org/doi/10.1098/rstl.1833.0016: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 053E.txt from https://www.gutenberg.org/files/29734/29734-h/29734-h.htm: 'str' object has no attribute 'get_text'\n",
            "Saved 054E.txt\n",
            "Failed to fetch 055E.txt from https://archive.org/details/b30795461: 'str' object has no attribute 'get_text'\n",
            "Saved 056E.txt\n",
            "Failed to fetch 057E.txt from https://archive.org/details/b22026290: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 058E.txt from https://archive.org/details/b28094414: 'str' object has no attribute 'get_text'\n",
            "Saved 059E.txt\n",
            "Failed to fetch 060E.txt from https://archive.org/details/dli.granth.111888/page/n5/mode/2up: 'str' object has no attribute 'get_text'\n",
            "Saved 061E.txt\n",
            "Saved 062E.txt\n",
            "Failed to fetch 063E.txt from https://archive.org/details/toiletofflora00buch: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 064E.txt from https://archive.org/details/b28766209: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 065E.txt from https://archive.org/details/in.ernet.dli.2015.115078/page/n35/mode/2up: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 066E.txt from https://archive.org/details/bookofscentedgar00burb/page/n15/mode/2up: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 067E.txt from https://archive.org/details/warpolicewatchdo00rich: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 068E.txt from https://archive.org/details/b20398505: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 069E.txt from https://theatregoing.wordpress.com/2016/12/01/two-views-of-a-cheap-theatre/: 'str' object has no attribute 'get_text'\n",
            "Saved 070E.txt\n",
            "Failed to fetch 071E.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Saved 072E.txt\n",
            "Saved 073E.txt\n",
            "Failed to fetch 074E.txt from https://www.gutenberg.org/files/10/10-h/10-h.htm: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 075E.txt from https://archive.org/details/thecaseforincens00unknuoft: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 076E.txt from ECCO (Via inger): Invalid URL 'ECCO (Via inger)': No scheme supplied. Perhaps you meant https://ECCO (Via inger)?\n",
            "Saved 077E.txt\n",
            "Failed to fetch 078E.txt from https://archive.org/details/b30779054/page/14/mode/2up?q=smell+scent: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 079E.txt from https://archive.org/details/b29323022: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 080E.txt from https://archive.org/details/b21529619: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 081E.txt from https://archive.org/details/b21529991_00022: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 082E.txt from https://www.gutenberg.org/cache/epub/10136/pg10136.html: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 083E.txt from https://archive.org/details/b28089893/page/n5/mode/2up: 'str' object has no attribute 'get_text'\n",
            "Failed to fetch 084E.txt from https://archive.org/details/b29820042: 'str' object has no attribute 'get_text'\n",
            "Saved 085E.txt\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
            "Failed to fetch nan.txt from nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/Odeuropa/books_converter.py \\\n",
        "  --folder /content/drive/MyDrive/Odeuropa/books_raw \\\n",
        "  --output /content/drive/MyDrive/Odeuropa/converted_books\\\n",
        "  --label EN \\\n",
        "  --books 1"
      ],
      "metadata": {
        "id": "dV9AQJ5m_0Mc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Odeuropa Smell Classifier"
      ],
      "metadata": {
        "id": "7ls4P2hnCp_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/Odeuropa/bert-base-uncased-odeuropa-20250607T180019Z-1-001.zip -d /content/drive/MyDrive/Odeuropa/model/"
      ],
      "metadata": {
        "id": "uqlMGB76_07s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 tqdm==4.63.0 transformers==4.17.0 seqeval[gpu]==1.2.2 sentencepiece==0.1.96 datasets==2.0.0 optuna==2.10.0"
      ],
      "metadata": {
        "id": "SA-7QNTS2A3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e92dfe1e-7ee6-4e7b-8913-b35538f75f81"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm==4.63.0 in /usr/local/lib/python3.11/dist-packages (4.63.0)\n",
            "Requirement already satisfied: transformers==4.17.0 in /usr/local/lib/python3.11/dist-packages (4.17.0)\n",
            "Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.11/dist-packages (from seqeval[gpu]==1.2.2) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.11/dist-packages (0.1.96)\n",
            "Requirement already satisfied: datasets==2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: optuna==2.10.0 in /usr/local/lib/python3.11/dist-packages (2.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (2.32.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (0.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0) (0.21.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval==1.2.2->seqeval[gpu]==1.2.2) (1.6.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->datasets==2.0.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (3.11.15)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.11/dist-packages (from datasets==2.0.0) (0.18.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from optuna==2.10.0) (1.16.2)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.11/dist-packages (from optuna==2.10.0) (4.10.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from optuna==2.10.0) (0.11.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==2.10.0) (6.9.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.11/dist-packages (from optuna==2.10.0) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from optuna==2.10.0) (2.0.41)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.0.0) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0) (2025.6.15)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->seqeval[gpu]==1.2.2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->seqeval[gpu]==1.2.2) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.1.0->optuna==2.10.0) (3.2.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic->optuna==2.10.0) (1.1.3)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna==2.10.0) (0.5.2)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna==2.10.0) (2.6.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna==2.10.0) (3.16.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna==2.10.0) (5.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.0.0) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.17.0) (8.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: pyperclip>=1.8 in /usr/local/lib/python3.11/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0) (1.9.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.10 in /usr/local/lib/python3.11/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.0.0) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=2.0.1->cliff->optuna==2.10.0) (6.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/Odeuropa/smell_classifier.py \\\n",
        "  --model_path \"/content/drive/MyDrive/Odeuropa/model/bert-base-uncased-odeuropa\" \\\n",
        "  --input_path \"/content/drive/MyDrive/Odeuropa/converted_books\" \\\n",
        "  --output_path \"/content/drive/MyDrive/Odeuropa/predictions\" \\\n",
        "  --lang \"english\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq-BMIaWKLGy",
        "outputId": "5701bd67-cdae-45c3-c0b1-56d6e100f69f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 16:37:52.256095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750437472.661849    8684 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750437472.772149    8684 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-20 16:37:53.625599: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/drive/MyDrive/Odeuropa/smell_classifier.py\", line 17, in <module>\n",
            "    from transformers import AutoModelForTokenClassification, Trainer, AutoConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/file_utils.py\", line 2767, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/file_utils.py\", line 2777, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 92, in <module>\n",
            "    from .trainer_pt_utils import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\", line 188, in <module>\n",
            "    device: Optional[torch.device] = torch.device(\"cuda\"),\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py:188: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: Optional[torch.device] = torch.device(\"cuda\"),\n",
            "Device is cpu.\n",
            "Loading the model checkpoint...\n",
            "Running the prediction for each file:\n",
            "Labeling /content/drive/MyDrive/Odeuropa/converted_books/books_merged_1.tsv... Number of unique sentences: 13414\n",
            "Parameter 'function'=<function main.<locals>.<lambda> at 0x7d9333f88ea0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100% 14/14 [00:06<00:00,  2.28ba/s]\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: word_labels, Document, Num, sentence. If word_labels, Document, Num, sentence are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 13414\n",
            "  Batch size = 8\n",
            "100% 1677/1677 [1:41:32<00:00,  2.17s/it]Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Odeuropa/smell_classifier.py\", line 264, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/Odeuropa/smell_classifier.py\", line 211, in main\n",
            "    predictions, labels, _ = test_trainer.predict(tokenized_test)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2331, in predict\n",
            "    output = eval_loop(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2475, in evaluation_loop\n",
            "    losses = nested_numpify(losses_host)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\", line 145, in nested_numpify\n",
            "    return t.numpy()\n",
            "           ^^^^^^^^^\n",
            "RuntimeError: Numpy is not available\n",
            "100% 1677/1677 [1:41:32<00:00,  3.63s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/Odeuropa/extract_annotations.py \\\n",
        "  --folder \"/content/drive/MyDrive/Odeuropa/predictions\" \\\n",
        "  --smellwordtag Smell_Word \\\n",
        "  --tags Smell_Source,Quality \\\n",
        "  --stopwords \"/content/drive/MyDrive/Odeuropa/stopwords.txt\" \\\n",
        "  --output \"/content/drive/MyDrive/Odeuropa/extracted_frame_elements.tsv\"\n"
      ],
      "metadata": {
        "id": "zK_kCRQPKDPu"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}